{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if IS_MASTER exists, this variable will only exist if it's being called by MASTER notebook.\n",
    "# if it does not exist, set it to False\n",
    "try: IS_MASTER\n",
    "except: IS_MASTER = False\n",
    "# The code below will only run if it's NOT being called from MASTER notebook\n",
    "if not IS_MASTER:\n",
    "    DATA_DIR = './data/temp/'\n",
    "    EXP_DIR = './exp/temp/'\n",
    "    PROCESSED_FILE = f'{DATA_DIR}processed.pkl'\n",
    "    MODEL_FILE = f'{EXP_DIR}model.pkl'\n",
    "    PREDICTION_FILE = f'{EXP_DIR}ypred.pkl'\n",
    "    OTHER_MODEL_PARAMETERS = ... # like N_ESTIMATOR, GAMMA, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:File `'plot_learning_curve.py'` not found.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "%matplotlib inline\n",
    "%run plot_learning_curve\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train, Optimize and Evaluate models\n",
    "======"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensembler\n",
    "======"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_LR = load('exp/models/model_LR.joblib')\n",
    "model_RF = load('exp/models/model_RF.joblib')\n",
    "model_ET = load('exp/models/model_ET.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hard\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85 (+/- 0.02) [Logistic Regression]\n",
      "Scores in every iteration [ 0.8375      0.87951807  0.83544304  0.90909091  0.74390244]\n",
      "Precision: 0.84 (+/- 0.11)\n",
      "Scores in every iteration [ 0.82716049  0.8902439   0.86842105  0.83333333  0.98387097]\n",
      "Recall: 0.88 (+/- 0.11)\n",
      "Scores in every iteration [ 0.83229814  0.88484848  0.8516129   0.86956522  0.84722222]\n",
      "F1: 0.86 (+/- 0.04)\n",
      "Accuracy: 0.85 (+/- 0.04) [Random Forest]\n",
      "Scores in every iteration [ 0.86666667  0.94202899  0.86567164  0.93442623  0.89655172]\n",
      "Precision: 0.90 (+/- 0.06)\n",
      "Scores in every iteration [ 0.67901235  0.82926829  0.76315789  0.78571429  0.90322581]\n",
      "Recall: 0.79 (+/- 0.15)\n",
      "Scores in every iteration [ 0.80821918  0.83783784  0.82269504  0.82666667  0.90598291]\n",
      "F1: 0.84 (+/- 0.07)\n",
      "Accuracy: 0.75 (+/- 0.06) [naive Bayes]\n",
      "Scores in every iteration [ 0.79069767  0.76404494  0.75581395  0.76923077  0.52586207]\n",
      "Precision: 0.72 (+/- 0.20)\n",
      "Scores in every iteration [ 0.83950617  0.82926829  0.85526316  0.83333333  0.98387097]\n",
      "Recall: 0.87 (+/- 0.12)\n",
      "Scores in every iteration [ 0.81437126  0.79532164  0.80246914  0.8         0.68539326]\n",
      "F1: 0.78 (+/- 0.09)\n",
      "Accuracy: 0.85 (+/- 0.01) [Ensemble]\n",
      "Scores in every iteration [ 0.85526316  0.88888889  0.86666667  0.90909091  0.74390244]\n",
      "Precision: 0.85 (+/- 0.11)\n",
      "Scores in every iteration [ 0.79012346  0.87804878  0.85526316  0.83333333  0.98387097]\n",
      "Recall: 0.87 (+/- 0.13)\n",
      "Scores in every iteration [ 0.82278481  0.88343558  0.87417219  0.86956522  0.84722222]\n",
      "F1: 0.86 (+/- 0.04)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Models/model_ENS_hard-d02.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "eclf = VotingClassifier(\n",
    "    estimators=[('lr', model_LR), ('rf', model_RF), ('et', model_ET)],\n",
    "    voting='hard')\n",
    "\n",
    "for clf, label in zip([model_LR, model_RF, model_ET, eclf], ['Logistic Regression', 'Random Forest', 'Extra Trees', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X, y, scoring='accuracy', cv=cv)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "    scores = cross_val_score(clf, X, y, cv=cv, scoring='precision')\n",
    "    print(\"Scores in every iteration\", scores)\n",
    "    print(\"Precision: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    scores = cross_val_score(clf, X, y, cv=cv, scoring='recall')\n",
    "    print(\"Scores in every iteration\", scores)\n",
    "    print(\"Recall: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    scores = cross_val_score(clf, X, y, cv=cv, scoring='f1')\n",
    "    print(\"Scores in every iteration\", scores)\n",
    "    print(\"F1: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "from joblib import dump, load\n",
    "dump(eclf, 'exp/models/model_ENS_hard.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soft\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85 (+/- 0.02) [Logistic Regression]\n",
      "Scores in every iteration [ 0.8375      0.87951807  0.83544304  0.90909091  0.74390244]\n",
      "Precision: 0.84 (+/- 0.11)\n",
      "Scores in every iteration [ 0.82716049  0.8902439   0.86842105  0.83333333  0.98387097]\n",
      "Recall: 0.88 (+/- 0.11)\n",
      "Scores in every iteration [ 0.83229814  0.88484848  0.8516129   0.86956522  0.84722222]\n",
      "F1: 0.86 (+/- 0.04)\n",
      "Accuracy: 0.86 (+/- 0.04) [Random Forest]\n",
      "Scores in every iteration [ 0.9137931   0.92857143  0.88059701  0.9516129   0.94915254]\n",
      "Precision: 0.92 (+/- 0.05)\n",
      "Scores in every iteration [ 0.66666667  0.7804878   0.73684211  0.66666667  0.85483871]\n",
      "Recall: 0.74 (+/- 0.14)\n",
      "Scores in every iteration [ 0.79710145  0.81632653  0.83916084  0.80555556  0.87804878]\n",
      "F1: 0.83 (+/- 0.06)\n",
      "Accuracy: 0.75 (+/- 0.06) [naive Bayes]\n",
      "Scores in every iteration [ 0.79069767  0.76404494  0.75581395  0.76923077  0.52586207]\n",
      "Precision: 0.72 (+/- 0.20)\n",
      "Scores in every iteration [ 0.83950617  0.82926829  0.85526316  0.83333333  0.98387097]\n",
      "Recall: 0.87 (+/- 0.12)\n",
      "Scores in every iteration [ 0.81437126  0.79532164  0.80246914  0.8         0.68539326]\n",
      "F1: 0.78 (+/- 0.09)\n",
      "Accuracy: 0.86 (+/- 0.02) [Ensemble]\n",
      "Scores in every iteration [ 0.86666667  0.87951807  0.85526316  0.90909091  0.74390244]\n",
      "Precision: 0.85 (+/- 0.11)\n",
      "Scores in every iteration [ 0.79012346  0.87804878  0.85526316  0.83333333  0.98387097]\n",
      "Recall: 0.87 (+/- 0.13)\n",
      "Scores in every iteration [ 0.82802548  0.88484848  0.86842105  0.87654321  0.84137931]\n",
      "F1: 0.86 (+/- 0.04)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Models/model_ENS_soft-d02.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eclf2 = VotingClassifier(\n",
    "    estimators=[('lr', model_LR), ('rf', model_RF), ('et', model_ET)],\n",
    "    voting='soft', weights=[1.5, 1.5, 1])\n",
    "\n",
    "for clf, label in zip([model_LR, model_RF, model_ET, eclf], ['Logistic Regression', 'Random Forest', 'Extra Trees', 'Ensemble']):\n",
    "    scores = cross_val_score(clf, X, y, scoring='accuracy', cv=cv)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "    scores = cross_val_score(clf, X, y, cv=cv, scoring='precision')\n",
    "    print(\"Scores in every iteration\", scores)\n",
    "    print(\"Precision: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    scores = cross_val_score(clf, X, y, cv=cv, scoring='recall')\n",
    "    print(\"Scores in every iteration\", scores)\n",
    "    print(\"Recall: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    scores = cross_val_score(clf, X, y, cv=cv, scoring='f1')\n",
    "    print(\"Scores in every iteration\", scores)\n",
    "    print(\"F1: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n",
    "from joblib import dump, load\n",
    "dump(eclf2, 'exp/models/model_ENS_soft.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
